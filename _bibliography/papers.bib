---
---
@article{yu2025your,
  title={Is Your Paper Being Reviewed by an LLM? Benchmarking AI Text Detection in Peer Review},
  author={Yu, Sungduk and Luo, Man and Madasu, Avinash and Lal, Vasudev and Howard, Phillip},
  booktitle = {ICLR},
  pdf={https://arxiv.org/pdf/2502.19614},
  year={2026},
  abbr={ICLR}
}

@inproceedings{stan2025learning,
  title     = {Learning from Reasoning Failures via Synthetic Data Generation},
  author    = {Stan, Gabriela Ben Melech and Aflalo, Estelle and Madasu, Avinash and Lal, Vasudev and Howard, Phillip},
  booktitle = {AAAI},
  pdf = {https://arxiv.org/pdf/2504.14523},
  year = {2026},
  abbr      = {AAAI}
}

@inproceedings{madasu2025pruning,
  title     = {Pruning the Paradox: How CLIP's Most Informative Heads Enhance Performance While Amplifying Bias},
  author    = {Madasu, Avinash and Lal, Vasudev and Howard, Phillip},
  booktitle = {EMNLP},
  pdf       = {https://arxiv.org/pdf/2503.11103}, 
  website   = {https://avinashsai.github.io/CCS-CLIP/},
  code      = {https://github.com/avinashsai/CCS-CLIP},
  note      = {<span style="color:red; font-weight:bold;">Oral presentation (Top 5% of papers, Senior Area Chair Recommendation)</span>},
  abbr      = {EMNLP},
  year      = {2025}
}


@inproceedings{madasu2025cultural,
  title     = {Cultural Awareness in Vision-Language Models: A Cross-Country Exploration},
  author    = {Madasu, Avinash and Lal, Vasudev and Howard, Phillip},
  booktitle = {CVPR (VLMs-4-All workshop)},
  year = {2025},
  pdf       = {https://openreview.net/pdf?id=TAuMAs3ftd},
  abbr      = {CVPR}
}

@inproceedings{yu2024your,
  title={Is Your Paper Being Reviewed by an LLM? Investigating AI Text Detectability in Peer Review},
  author={Yu, Sungduk and Luo, Man and Madasu, Avinash and Lal, Vasudev and Howard, Phillip},
  booktitle={NeurIPS (Safe Generative AI Workshop)},
  pdf={https://openreview.net/pdf?id=f2G7C2fKxV},
  abbr={NeurIPS},
  year={2024}
}

@inproceedings{haydarov2024affective,
  title={Affective Visual Dialog: A Large-Scale Benchmark for Emotional Reasoning based on Visually Grounded Conversations},
  author={Haydarov, Kilichbek and Shen, Xiaoqian and Madasu, Avinash and Salem, Mahmoud and Li, Li-Jia and Elsayed, Gamaleldin and Elhoseiny, Mohamed},
  booktitle={ECCV},
  year={2024},
  pdf={https://arxiv.org/pdf/2308.16349},
  website={https://affective-visual-dialog.github.io/},
  abbr={ECCV}
}


@article{madasu2024quantifying,
  title={Quantifying and Enabling the Interpretability of CLIP-like Models},
  author={Madasu, Avinash and Gandelsman, Yossi and Lal, Vasudev and Howard, Phillip},
  pdf={https://arxiv.org/pdf/2409.06579},
  website={https://intellabs.github.io/multimodal_cognitive_ai/CLIP-InterpreT/},
  year={2024},
  abbr={arXiv}
}

@inproceedings{howard2024socialcounterfactuals,
  title={Socialcounterfactuals: Probing and Mitigating Intersectional Social Biases in Vision-Language Models with Counterfactual Examples},
  author={Howard, Phillip and Madasu, Avinash and Le, Tiep and Moreno, Gustavo Lujan and Bhiwandiwalla, Anahita and Lal, Vasudev},
  booktitle={CVPR},
  pdf={https://openaccess.thecvf.com/content/CVPR2024/papers/Howard_SocialCounterfactuals_Probing_and_Mitigating_Intersectional_Social_Biases_in_Vision-Language_Models_CVPR_2024_paper.pdf},
  website={https://intellabs.github.io/multimodal_cognitive_ai/socialcounterfactuals/},
  year={2024},
  abbr={CVPR}
}

@article{firdaus2024unified,
  title={A Unified Framework for Slot based Response Generation in a Multimodal Dialogue System},
  author={Firdaus, Mauajama and Madasu, Avinash and Ekbal, Asif},
  journal={Multimedia Tools and Applications},
  year={2024},
  abbr={Journal},
  pdf={https://link.springer.com/article/10.1007/s11042-023-15915-8}
}

@article{madasu2023mumur,
  title={MuMUR: Multilingual Multimodal Universal Retrieval},
  author={Madasu, Avinash and Aflalo, Estelle and Stan, Gabriela Ben Melech and Rosenman, Shachar and Tseng, Shao-Yen and Bertasius, Gedas and Lal, Vasudev},
  journal={Information Retrieval Journal},
  year={2023},
  abbr={Journal},
  pdf={https://link.springer.com/article/10.1007/S10791-023-09422-5}
}

@inproceedings{madasuanalyzing,
  title={Analyzing Zero-Shot Abilities of Vision-Language Models on Video Understanding Tasks},
  author={Madasu, Avinash and Bhiwandiwalla, Anahita and Lal, Vasudev},
  booktitle={NeurIPS (R0-FoMo workshop)},
  year={2023},
  abbr={NeurIPS},
  pdf={https://openreview.net/pdf?id=ikSuM1txmW}
}

@inproceedings{madasu2024icsvr,
  title={ICSVR: Investigating Compositional and Syntactic understanding in Video Retrieval Models},
  author={Madasu, Avinash and Lal, Vasudev},
  booktitle={CVPR (MMFM workshop)},
  abbr={CVPR},
  pdf={https://openaccess.thecvf.com/content/CVPR2024W/MMFM/papers/Madasu_ICSVR_Investigating_Compositional_and_Syntactic_Understanding_in_Video_Retrieval_Models_CVPRW_2024_paper.pdf},
  year={2024}
}

@inproceedings{madasu2023multimodal,
  title={Is Multimodal Vision Supervision Beneficial to Language?},
  author={Madasu, Avinash and Lal, Vasudev},
  booktitle={CVPR (NFVLR workshop)},
  pdf={https://openaccess.thecvf.com/content/CVPR2023W/NFVLR/papers/Madasu_Is_Multimodal_Vision_Supervision_Beneficial_to_Language_CVPRW_2023_paper.pdf},
  year={2023},
  abbr={CVPR}
}

@inproceedings{madasu2023improving,
  title={Improving Video Retrieval using Multilingual Knowledge Transfer},
  author={Madasu, Avinash and Aflalo, Estelle and Ben Melech Stan, Gabriela and Tseng, Shao-Yen and Bertasius, Gedas and Lal, Vasudev},
  booktitle={ECIR},
  abbr={ECIR},
  year={2023},
  pdf={https://dl.acm.org/doi/10.1007/978-3-031-28244-7_42},
  note={<span style="color:red; font-weight:bold;">Best Student Paper Award</span>},
}

@inproceedings{madasu2022large,
  title={What do Large Language Models Learn beyond Language?},
  author={Madasu, Avinash and Srivastava, Shashank},
  booktitle={EMNLP (findings)},
  pdf={https://aclanthology.org/2022.findings-emnlp.516.pdf},
  year={2022},
  abbr={EMNLP}
}

@inproceedings{madasu2022learning,
  title={Learning to Retrieve Videos by Asking Questions},
  author={Madasu, Avinash and Oliva, Junier and Bertasius, Gedas},
  booktitle={ACM Multimedia},
  pdf={https://dl.acm.org/doi/pdf/10.1145/3503161.3548361},
  abbr={ACM Multimedia},
  year={2022}
}

@inproceedings{madasu2021sequential,
  title={Sequential Domain Adaptation through Elastic Weight Consolidation for Sentiment Analysis},
  author={Madasu, Avinash and Vijjini, Anvesh Rao},
  booktitle={ICPR},
  pdf={https://arxiv.org/pdf/2007.01189},
  year={2021},
  abbr={ICPR}
}

@inproceedings{madasu2020position,
  title={A Position Aware Decay Weighted Network for Aspect Based Sentiment Analysis},
  author={Madasu, Avinash and Rao, Vijjini Anvesh},
  booktitle={NLDB},
  pdf={https://arxiv.org/pdf/2005.01027},
  year={2020},
  abbr={NLDB}
}

@article{madasu2020efficient,
  title={Efficient Feature Selection Techniques for Sentiment Analysis},
  author={Madasu, Avinash and Elango, Sivasankar},
  journal={Multimedia Tools and Applications},
  pdf={https://arxiv.org/pdf/1911.00288},
  year={2020},
  abbr={Journal}
}

@inproceedings{madasu2019sequential,
  title={Sequential Learning of Convolutional Features for Effective Text Classification},
  author={Madasu, Avinash and Rao, Vijjini Anvesh},
  booktitle={EMNLP},
  pdf={https://aclanthology.org/D19-1567.pdf},
  year={2019},
  abbr={EMNLP}
}

@inproceedings{madasu2019gated,
  title={Gated Convolutional Neural Networks for Domain Adaptation},
  author={Madasu, Avinash and Rao, Vijjini Anvesh},
  booktitle={NLDB},
  pdf={https://arxiv.org/pdf/1905.06906},
  year={2019},
  abbr={NLDB}
}

@inproceedings{madasu2019effectiveness,
  title={Effectiveness of Self Normalizing Neural Networks for Text Classification},
  author={Madasu, Avinash and Rao, Vijjini Anvesh},
  booktitle={CICLing},
  pdf={https://arxiv.org/pdf/1905.01338},
  year={2019},
  abbr={CICLing}
}

@incollection{avinash2018study,
  title={A Study of Feature Extraction Techniques for Sentiment Analysis},
  author={Madasu, Avinash and E, Sivasankar},
  booktitle={IEMIS},
  year={2018},
  pdf={https://arxiv.org/pdf/1906.01573},
  abbr={IEMIS}
}
