---
---
@inproceedings{madasu2025cultural,
  title     = {Cultural Awareness in Vision-Language Models: A Cross-Country Exploration},
  author    = {{\textbf{\underline{\color{red} Madasu, Avinash}}} and Lal, Vasudev and Howard, Phillip},
  booktitle = {CVPR (VLMs-4-All workshop)},
  year = {2025},
  pdf       = {https://openreview.net/pdf?id=TAuMAs3ftd},
  abbr      = {CVPR}
}

@inproceedings{stan2025learning,
  title     = {Learning from Reasoning Failures via Synthetic Data Generation},
  author    = {Stan, Gabriela Ben Melech and Aflalo, Estelle and <b><u><span style="color:red;">Madasu, Avinash</span></u></b> and Lal, Vasudev and Howard, Phillip},
  booktitle = {CVPR (SynData4CV Workshop)},
  pdf = {https://arxiv.org/pdf/2504.14523},
  year = {2025},
  arxiv     = {2501.01234},
  abbr      = {CVPR}
}

@inproceedings{madasu2025pruning,
  title     = {Pruning the Paradox: How CLIP's Most Informative Heads Enhance Performance While Amplifying Bias},
  author    = {<b><u><span style="color:red;">Madasu, Avinash</span></u></b> and Lal, Vasudev and Howard, Phillip},
  booktitle = {EMNLP},
  pdf       = {https://arxiv.org/pdf/2503.11103},
  arxiv     = {2503.11103},    
  website   = {https://dummy-project-website.com},
  note      = {<span style="color:green;">(Oral)</span>},
  abbr      = {EMNLP},
  year      = {2025}
}

@article{yu2025your,
  title={Is Your Paper Being Reviewed by an LLM? A New Benchmark Dataset and Approach for Detecting AI Text in Peer Review},
  author={Yu, Sungduk and Luo, Man and <b><u><span style="color:red;">Madasu, Avinash</span></u></b> and Lal, Vasudev and Howard, Phillip},
  abbr={arXiv},
  pdf={https://arxiv.org/pdf/2502.19614},
  arxiv={2502.19614},
  year={2025}
}

@inproceedings{yu2024your,
  title={Is Your Paper Being Reviewed by an LLM? Investigating AI Text Detectability in Peer Review},
  author={Yu, Sungduk and Luo, Man and <b><u><span style="color:red;">Madasu, Avinash</span></u></b> and Lal, Vasudev and Howard, Phillip},
  booktitle={NeurIPS (Safe Generative AI Workshop)},
  pdf={https://openreview.net/pdf?id=f2G7C2fKxV},
  abbr={NeurIPS},
  year={2024}
}

@inproceedings{haydarov2024affective,
  title={Affective visual dialog: A large-scale benchmark for emotional reasoning based on visually grounded conversations},
  author={Haydarov, Kilichbek and Shen, Xiaoqian and <b><u><span style="color:red;">Madasu, Avinash</span></u></b> and Salem, Mahmoud and Li, Li-Jia and Elsayed, Gamaleldin and Elhoseiny, Mohamed},
  booktitle={ECCV},
  year={2024},
  pdf={https://arxiv.org/pdf/2308.16349},
  website={https://affective-visual-dialog.github.io/},
  abbr={ECCV}
}


@article{madasu2024quantifying,
  title={Quantifying and Enabling the Interpretability of CLIP-like Models},
  author={<b><u><span style="color:red;">Madasu, Avinash</span></u></b> and Gandelsman, Yossi and Lal, Vasudev and Howard, Phillip},
  abbr={arXiv},
  arxiv={2409.06579},
  pdf={https://arxiv.org/pdf/2409.06579},
  year={2024}
}

@inproceedings{howard2024socialcounterfactuals,
  title={Socialcounterfactuals: Probing and mitigating intersectional social biases in vision-language models with counterfactual examples},
  author={Howard, Phillip and <b><u><span style="color:red;">Madasu, Avinash</span></u></b> and Le, Tiep and Moreno, Gustavo Lujan and Bhiwandiwalla, Anahita and Lal, Vasudev},
  booktitle={CVPR},
  pdf={https://openaccess.thecvf.com/content/CVPR2024/papers/Howard_SocialCounterfactuals_Probing_and_Mitigating_Intersectional_Social_Biases_in_Vision-Language_Models_CVPR_2024_paper.pdf},
  website={https://intellabs.github.io/multimodal_cognitive_ai/socialcounterfactuals/},
  year={2024},
  abbr={CVPR}
}
